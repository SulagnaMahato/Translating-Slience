# Translating-Silence

Translating-Silence is a computer vision-powered system designed to translate American Sign Language (ASL) into text in real-time. The aim is to enhance accessibility and bridge communication gaps for the deaf and hard-of-hearing communities using machine learning.

## 🚀 Features

- 🎥 Real-time sign language detection using a webcam
- 🧠 ISL gesture recognition using machine learning
- 🖥️ Live text output of detected gestures
- 🔧 Easy to modify and expand for more gestures/languages

## 🛠️ Installation

```bash
git clone https://github.com/HARAJIT05/Translating-Silence.git
cd Translating-Silence
pip install -r requirements.txt
```

Make sure Python and OpenCV are installed on your machine.

## ▶️ Usage

To start the application:

```bash
python main.py
```

- Sign using ASL in front of your webcam.
- The model will recognize gestures and display corresponding text on the interface.

## 🗂️ Project Structure

```plaintext
Translating-Silence/
│
├── main.py                 # Main script to run the application
├── model/                  # Trained ML model for ASL recognition
├── templates/              # HTML templates if using web-based output
├── static/                 # Static files like images or stylesheets
└── README.md               # Project documentation
```

## 📷 Demo

*Coming Soon:* A sample demo video or GIF showing the app in action.

## 🤝 Contributing

Contributions are welcome! Here's how you can help:

1. Fork the repo
2. Create your branch (`git checkout -b feature-name`)
3. Commit changes (`git commit -am 'Add feature'`)
4. Push to the branch (`git push origin feature-name`)
5. Open a Pull Request

## 👤 Contributors

<table>
  <tr>
    <td align="center">
      <a href="https://github.com/HARAJIT05">
        <img src="https://avatars.githubusercontent.com/u/110291590?v=4" width="100px;" alt="Harajit Das"/><br />
        <sub><b>HARAJIT05</b></sub>
      </a>
    </td>
  </tr>
</table>

## 📄 License

This project is licensed under the [MIT License](LICENSE).
